{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe01e5fe-79cc-4b3e-a2d4-430be9c4ad57",
   "metadata": {},
   "source": [
    "# Codificação de Variáveis Textuais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59882578-7de9-4312-8186-b5e1b2a5a54d",
   "metadata": {},
   "source": [
    "## Motivação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad54b48-2e72-46f4-bd54-9f077cf1ac82",
   "metadata": {},
   "source": [
    "A codificação de variáveis textuais consiste na transformação de um conjunto de elementos textuais em um conjunto de dados organizado sob um determinado aspecto, sendo, portanto, um importante instrumento para o processamento de linguagem natural e para a recuperação de informações.\n",
    "Um exemplo de aplicação prática da codificação de variáveis textuais é a filtragem de e-mais de spam, que pode ser realizada a partir da identificação de padrões de dados relacionados a palavras em e-mails dessa natureza."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9107d600-7c19-4890-b363-7913f1864864",
   "metadata": {},
   "source": [
    "Há dois principais tipos de codificação:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a83288-fec3-48c1-93e9-978f48eacd40",
   "metadata": {},
   "source": [
    "- ### Bag-of-Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4935e1bc-d0b7-4397-93ea-199066986406",
   "metadata": {},
   "source": [
    "Nesse modelo, o texto é representado como uma bolsa (Bag) de suas palavras (Words), desconsiderando aspectos gramaticais e a ordem em que elas são apresentadas, mas mantendo a multiplicidade (número de observações). Nesse sentido, essa técnica é altamente eficaz para o treinamento de modelos classificadores, uma vez que a informação sobre a frequência de cada palavra é obtida facilmente. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85346da4-05e7-4d8b-99f7-f8d4460b96d2",
   "metadata": {},
   "source": [
    "Na prática, esse modelo é usado, principalmente, como ferramenta de geração de atributos, uma vez que, após a quebra do texto em palavras, pode-se calcular vários parâmetros para caracterizá-lo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d384cbc3-ad16-4fd5-91ed-b599b33bdfbc",
   "metadata": {},
   "source": [
    "- ### Tf-Idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e6bc0a-1436-4d85-9b22-884cd4d3aca2",
   "metadata": {},
   "source": [
    "No modelo de codificação Termo Frequency-Inverse Document Frequency (Tf-Idf), é utilizada uma estatística numérica para estimar a importância de uma palavra para um texto que pertence a uma coleção, sendo esse modelo frequentemente utilizado como fator de ponderação em recuperação de informações e mineração de texto. Essa estatística baseia-se na relação entre a frequência da palavra no texto e o número de textos que contém a palavra, o que ajuda a compensar o fato de algumas palavras aparecerem com bastante frequência na grande maioria dos textos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6b7eb-d564-4020-af5e-4b88b17225b1",
   "metadata": {},
   "source": [
    "Na prática, esse modelo é usado, principalmente, por mecanismos de pesquisa como uma ferramenta para pontuação e classificação da relevância de um documento para uma determinada consulta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b7839a-ed6b-4c75-acae-c1563338385f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f577bf3c-cc02-4d4a-a9b8-7718437148c6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093bdcc0-5d79-415b-9836-a7b905d23da9",
   "metadata": {},
   "source": [
    "## Prática"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da7a755-58bf-44e6-8851-6b3bff0bcb0b",
   "metadata": {},
   "source": [
    "### Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8257bb8f-fc0a-4acf-b8ad-879cc1ff9f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from typing import List\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "34ba98cd-fcb7-4041-a855-6bc91d460130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-Words:\n",
      "{'john': 1, 'likes': 4, 'to': 2, 'watch': 2, 'movies': 3, 'mary': 1, 'too': 1}\n"
     ]
    }
   ],
   "source": [
    "def bagOfWords(sentences: List[str]) -> List:\n",
    "    \n",
    "    bow = {}\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence = [sentence.lower()]\n",
    "    \n",
    "        tokenizer = Tokenizer()\n",
    "        tokenizer.fit_on_texts(sentence)\n",
    "        sequences = tokenizer.texts_to_sequences(sentence)\n",
    "        word_index = tokenizer.word_index \n",
    "\n",
    "        for key in word_index:\n",
    "            try:\n",
    "                bow[key] += sequences[0].count(word_index[key])\n",
    "            except:\n",
    "                bow[key] = sequences[0].count(word_index[key])\n",
    "\n",
    "    return bow\n",
    "    \n",
    "    \n",
    "frases = [\n",
    "    \"John likes\",\n",
    "    \"likes to\",\n",
    "    \"to watch\",\n",
    "    \"watch movies\",\n",
    "    \"Mary likes\",\n",
    "    \"likes movies\",\n",
    "    \"movies too\",\n",
    "]\n",
    " \n",
    "    \n",
    "print(\"Bag-of-Words:\")\n",
    "print(bagOfWords(frases))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dccb865-bee4-4ef0-aa75-60add0a6a94b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e024d06-2642-4108-9da9-582f9f2f6abf",
   "metadata": {},
   "source": [
    "### Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fa9ceb57-7fea-4435-acf7-da6be12e7194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tf-Idf:\n",
      "{'john': 0.626381484247684, 'likes': 0.16823611831060645}\n"
     ]
    }
   ],
   "source": [
    "def contains_word(word, sentence: List[str]) -> bool:\n",
    "    word = word.lower()\n",
    "    sentence = [sentence.lower()]\n",
    "    \n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(sentence)\n",
    "    sequences = tokenizer.texts_to_sequences(sentence)\n",
    "    word_index = tokenizer.word_index \n",
    "\n",
    "    for key in word_index:\n",
    "        if key == word:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "def tf_idf(document: List[str], documents: List[str]) -> List:\n",
    "    \n",
    "    bow_document = bagOfWords(document)\n",
    "    bow_tfidf = {}\n",
    "    \n",
    "    for k, v in bow_document.items():\n",
    "        count_word = 0\n",
    "        tf = v/len(bow_document)\n",
    "        \n",
    "        for text in documents:\n",
    "            if contains_word(k,text):\n",
    "                count_word += 1\n",
    "        \n",
    "        idf = np.log(len(documents)/(1+count_word))\n",
    "        \n",
    "        bow_tfidf[k] = tf*idf       \n",
    "    \n",
    "    return bow_tfidf\n",
    "\n",
    "\n",
    "print(\"Tf-Idf:\")\n",
    "print(tf_idf([frases[0]],frases))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
